{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba0c0a19",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1999d044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416b70b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from nltk import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2affa893",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09c0a7f",
   "metadata": {},
   "source": [
    "Loading data from csv files. Titles has contains user-voted on titles that have been voted on. Info contains raw data from the videos, including the posted title on youtube. It contains over 7 million entries. Titles only has 145,000 entries so I'll left merge to only keep the entries that have the voted on titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4a7559",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = pd.read_csv('/Volumes/Samsung_T5/sb-mirror/titles.csv')\n",
    "info = pd.read_csv('/Volumes/Samsung_T5/sb-mirror/videoInfo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458943df",
   "metadata": {},
   "outputs": [],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7209f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9a9f32",
   "metadata": {},
   "source": [
    "I'm limiting the info dataframe to just the unique videoID and the title. Then I am renaming the \"title\" column in the titles dataframe for the merging process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba7f59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_title = info[['videoID','title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038728bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles.rename(columns={\"title\":\"other_title\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3985952",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df = pd.merge(titles,info_title,how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b183d6",
   "metadata": {},
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f7bdce",
   "metadata": {},
   "source": [
    "The original column seems to indicate that the video's title was not deemed \"clickbaity\" enough by the voters and was fine to remain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0b4afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df[title_df['original']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3683a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df['original'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4f775c",
   "metadata": {},
   "source": [
    "Only 5 Percent of the dataset is \"original title.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1841d596",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df[title_df['original']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5d756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb948b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df['title'].isna().mean()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4cf356",
   "metadata": {},
   "source": [
    "41% of the titles are nans, meaning I have to drop them from the dataset to really be able to guage the success of the chatgpt vs the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4d5d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237b748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a26bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbb0184",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df.to_csv('titles_no_nan.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234b60f3",
   "metadata": {},
   "source": [
    "## Title Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6a1cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(title_df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d0f9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07388eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2430d11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_text = ' '.join(title_df['other_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e15bce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_text_cloud = WordCloud(width=800, height=400, background_color='white').generate(other_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334293d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a542a335",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a98fe0",
   "metadata": {},
   "source": [
    "# ChatGPT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056fafbc",
   "metadata": {},
   "source": [
    "This is my attempt to use ChatGPT to classify the clickbait titles and see how it performs against other models. It is neccesary to set up a ChatGPT API key to perform this action. I will link to how to perform this action. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd64010",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = title_df.sample()['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98365d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[48248]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bd956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cf9524",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df.iloc[48248]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94473dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Classify the text into one of the classes. Also return the probability of it being clickbait.\n",
    "Classes: [`clickbait`, `not clickbait`]\n",
    "Text: World's first screw-bike\n",
    "Class: `not clickbait`\n",
    "\n",
    "Text: Mastering mood in photography (3 easy steps).\n",
    "Class: `not clickbait`\n",
    "\n",
    "Text: What's Inside the DON'T DIE BOX???.\n",
    "Class: `clickbait`\n",
    "\n",
    "Text: 'OBNOXIOUS Idiot Pushes The WRONG JUDGE Too Far!!! Wild Court Cam...'\n",
    "Class: 'clickbait'\n",
    "\n",
    "Text: {test}\n",
    "Class: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd44f6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51f25a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate completion using OpenAI's GPT-3.5 model\n",
    "response = openai.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "\n",
    "# Extract the generated classification label and probability\n",
    "output = response\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfaccf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment-env",
   "language": "python",
   "name": "sentiment_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
